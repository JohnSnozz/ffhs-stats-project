{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# PCA-Analyse der Schweizer Abstimmungsdaten\n\nDiese Analyse untersucht die politischen Dimensionen im Abstimmungsverhalten der Schweizer Gemeinden.\n\n**Basierend auf:** Hermann & Leuthold - Der politische Raum der Schweiz\n\n**Die drei Dimensionen:**\n1. **PC1: Liberal ↔ Konservativ** (gesellschaftlich: Einbürgerung, EU, Ausländerpolitik)\n2. **PC2: Establishment ↔ Populistisch** (Regierungstreue vs. populistische Initiativen)\n3. **PC3: Ökologisch ↔ Technokratisch** (Umwelt, Energie, Pestizide)\n\n**Wichtiger Hinweis zu PC2:**\nDie wirtschaftliche Links-Rechts-Dimension ist nicht eindeutig von PC2 abgebildet. \nPC2 trennt primär zwischen:\n- **Establishment** (Goldküste: folgt Bundesratsempfehlungen bei AHV-Reformen)\n- **Populistisch** (Innerschweiz: gegen Rentenaltererhöhung, für populistische Initiativen)\n\nDies erklärt, warum die konservative Innerschweiz (SVP) auf PC2 ähnlich wie linke Gemeinden erscheint.\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup und Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Plot-Einstellungen\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Datenbankverbindung\n",
    "DB_PATH = '../data/processed/swiss_votings.db'\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "print(\"Verbindung zur Datenbank hergestellt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstimmungsdaten laden\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    municipality_id,\n",
    "    municipality_name,\n",
    "    proposal_id,\n",
    "    voting_date,\n",
    "    title_de,\n",
    "    ja_prozent\n",
    "FROM v_voting_results_analysis\n",
    "WHERE ja_prozent IS NOT NULL\n",
    "ORDER BY municipality_id, voting_date, proposal_id\n",
    "\"\"\"\n",
    "\n",
    "df_raw = pd.read_sql_query(query, conn)\n",
    "print(f\"Rohdaten geladen: {len(df_raw):,} Zeilen\")\n",
    "print(f\"Gemeinden: {df_raw['municipality_id'].nunique()}\")\n",
    "print(f\"Abstimmungsvorlagen: {df_raw['proposal_id'].nunique()}\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datenmatrix erstellen (Gemeinden × Vorlagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot: Zeilen = Gemeinden, Spalten = Abstimmungsvorlagen\n",
    "# Werte = Ja-Prozent\n",
    "\n",
    "df_pivot = df_raw.pivot_table(\n",
    "    index=['municipality_id', 'municipality_name'],\n",
    "    columns='proposal_id',\n",
    "    values='ja_prozent',\n",
    "    aggfunc='first'  # Sollte keine Duplikate geben\n",
    ")\n",
    "\n",
    "print(f\"Matrix-Dimensionen: {df_pivot.shape[0]} Gemeinden × {df_pivot.shape[1]} Vorlagen\")\n",
    "print(f\"\\nFehlende Werte pro Vorlage (erste 10):\")\n",
    "print(df_pivot.isnull().sum().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fehlende Werte analysieren\n",
    "missing_per_municipality = df_pivot.isnull().sum(axis=1)\n",
    "missing_per_proposal = df_pivot.isnull().sum(axis=0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Fehlende Werte pro Gemeinde\n",
    "axes[0].hist(missing_per_municipality, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Anzahl fehlender Vorlagen')\n",
    "axes[0].set_ylabel('Anzahl Gemeinden')\n",
    "axes[0].set_title('Fehlende Werte pro Gemeinde')\n",
    "axes[0].axvline(missing_per_municipality.median(), color='red', linestyle='--', \n",
    "                label=f'Median: {missing_per_municipality.median():.0f}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Fehlende Werte pro Vorlage\n",
    "axes[1].hist(missing_per_proposal, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_xlabel('Anzahl fehlender Gemeinden')\n",
    "axes[1].set_ylabel('Anzahl Vorlagen')\n",
    "axes[1].set_title('Fehlende Werte pro Vorlage')\n",
    "axes[1].axvline(missing_per_proposal.median(), color='red', linestyle='--',\n",
    "                label=f'Median: {missing_per_proposal.median():.0f}')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('missing_values_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nGemeinden mit >50% fehlenden Werten: {(missing_per_municipality > df_pivot.shape[1]/2).sum()}\")\n",
    "print(f\"Vorlagen mit >50% fehlenden Gemeinden: {(missing_per_proposal > df_pivot.shape[0]/2).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entscheidung: Gemeinden und Vorlagen mit zu vielen fehlenden Werten entfernen\n",
    "# Dann restliche NaN mit Spalten-Mittelwert imputieren\n",
    "\n",
    "# Threshold: Max 20% fehlende Werte\n",
    "MAX_MISSING_RATIO = 0.20\n",
    "\n",
    "# Vorlagen filtern\n",
    "valid_proposals = missing_per_proposal[missing_per_proposal <= df_pivot.shape[0] * MAX_MISSING_RATIO].index\n",
    "df_filtered = df_pivot[valid_proposals]\n",
    "print(f\"Nach Vorlagen-Filter: {df_filtered.shape[1]} Vorlagen behalten (von {df_pivot.shape[1]})\")\n",
    "\n",
    "# Gemeinden filtern\n",
    "missing_per_municipality_filtered = df_filtered.isnull().sum(axis=1)\n",
    "valid_municipalities = missing_per_municipality_filtered[missing_per_municipality_filtered <= df_filtered.shape[1] * MAX_MISSING_RATIO].index\n",
    "df_filtered = df_filtered.loc[valid_municipalities]\n",
    "print(f\"Nach Gemeinden-Filter: {df_filtered.shape[0]} Gemeinden behalten (von {df_pivot.shape[0]})\")\n",
    "\n",
    "print(f\"\\nFinale Matrix: {df_filtered.shape[0]} × {df_filtered.shape[1]}\")\n",
    "print(f\"Verbleibende NaN: {df_filtered.isnull().sum().sum()} ({100*df_filtered.isnull().sum().sum()/(df_filtered.shape[0]*df_filtered.shape[1]):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation: Fehlende Werte mit Spalten-Mittelwert (= Durchschnitt der Vorlage) füllen\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(df_filtered)\n",
    "\n",
    "# DataFrame für spätere Referenz\n",
    "df_imputed = pd.DataFrame(\n",
    "    X_imputed, \n",
    "    index=df_filtered.index, \n",
    "    columns=df_filtered.columns\n",
    ")\n",
    "\n",
    "print(f\"Imputation abgeschlossen. Shape: {df_imputed.shape}\")\n",
    "print(f\"Verbleibende NaN: {df_imputed.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Standardisierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Standardisierung (wichtig für PCA)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_imputed)\n",
    "\n",
    "print(f\"Standardisierte Matrix: {X_scaled.shape}\")\n",
    "print(f\"Mittelwert (sollte ~0 sein): {X_scaled.mean():.6f}\")\n",
    "print(f\"Std (sollte ~1 sein): {X_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bestimmung der optimalen Faktorenzahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vollständige PCA für Scree-Plot\n",
    "pca_full = PCA()\n",
    "pca_full.fit(X_scaled)\n",
    "\n",
    "# Eigenwerte und erklärte Varianz\n",
    "eigenvalues = pca_full.explained_variance_\n",
    "explained_variance_ratio = pca_full.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "print(\"Erste 10 Komponenten:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'PC':>4} {'Eigenwert':>12} {'Varianz %':>12} {'Kumulativ %':>12}\")\n",
    "print(\"-\" * 60)\n",
    "for i in range(10):\n",
    "    print(f\"{i+1:>4} {eigenvalues[i]:>12.3f} {explained_variance_ratio[i]*100:>11.2f}% {cumulative_variance[i]*100:>11.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scree-Plot und kumulative Varianz\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Scree-Plot (erste 20 Komponenten)\n",
    "n_show = 20\n",
    "axes[0].plot(range(1, n_show+1), eigenvalues[:n_show], 'bo-', markersize=8)\n",
    "axes[0].axhline(y=1, color='r', linestyle='--', label='Kaiser-Kriterium (Eigenwert = 1)')\n",
    "axes[0].set_xlabel('Hauptkomponente')\n",
    "axes[0].set_ylabel('Eigenwert')\n",
    "axes[0].set_title('Scree-Plot')\n",
    "axes[0].set_xticks(range(1, n_show+1))\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Kumulative erklärte Varianz\n",
    "axes[1].plot(range(1, n_show+1), cumulative_variance[:n_show]*100, 'go-', markersize=8)\n",
    "axes[1].axhline(y=70, color='orange', linestyle='--', label='70% Varianz')\n",
    "axes[1].axhline(y=80, color='red', linestyle='--', label='80% Varianz')\n",
    "axes[1].set_xlabel('Anzahl Hauptkomponenten')\n",
    "axes[1].set_ylabel('Kumulative erklärte Varianz (%)')\n",
    "axes[1].set_title('Kumulative erklärte Varianz')\n",
    "axes[1].set_xticks(range(1, n_show+1))\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('scree_plot.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Kaiser-Kriterium\n",
    "n_kaiser = np.sum(eigenvalues > 1)\n",
    "print(f\"\\nKaiser-Kriterium: {n_kaiser} Komponenten haben Eigenwert > 1\")\n",
    "print(f\"Diese erklären {cumulative_variance[n_kaiser-1]*100:.1f}% der Varianz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailanalyse: Wieviele Faktoren sind sinnvoll?\n",
    "print(\"Analyse der Faktorenzahl:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Kaiser-Kriterium\n",
    "print(f\"\\n1. Kaiser-Kriterium (Eigenwert > 1): {n_kaiser} Faktoren\")\n",
    "\n",
    "# Elbow-Methode (manuell identifizieren)\n",
    "eigenvalue_diffs = np.diff(eigenvalues[:10])\n",
    "print(f\"\\n2. Eigenwert-Differenzen (für Elbow):\")\n",
    "for i, diff in enumerate(eigenvalue_diffs):\n",
    "    print(f\"   PC{i+1} → PC{i+2}: {diff:.3f}\")\n",
    "\n",
    "# 70% und 80% Varianz\n",
    "n_70 = np.argmax(cumulative_variance >= 0.70) + 1\n",
    "n_80 = np.argmax(cumulative_variance >= 0.80) + 1\n",
    "print(f\"\\n3. Für 70% erklärte Varianz: {n_70} Faktoren\")\n",
    "print(f\"   Für 80% erklärte Varianz: {n_80} Faktoren\")\n",
    "\n",
    "# Empfehlung basierend auf Literatur\n",
    "print(f\"\\n4. Literatur (Hermann & Leuthold): 2-3 Faktoren\")\n",
    "print(f\"   - 2 ausgeprägte Dimensionen\")\n",
    "print(f\"   - 1 'halbe' Dimension (weniger stabil)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PCA mit 2 Faktoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA mit 2 Komponenten\n",
    "pca_2 = PCA(n_components=2)\n",
    "scores_2 = pca_2.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"PCA mit 2 Faktoren:\")\n",
    "print(f\"  Erklärte Varianz PC1: {pca_2.explained_variance_ratio_[0]*100:.2f}%\")\n",
    "print(f\"  Erklärte Varianz PC2: {pca_2.explained_variance_ratio_[1]*100:.2f}%\")\n",
    "print(f\"  Total: {pca_2.explained_variance_ratio_.sum()*100:.2f}%\")\n",
    "\n",
    "# Scores DataFrame\n",
    "df_scores_2 = pd.DataFrame(\n",
    "    scores_2,\n",
    "    columns=['PC1', 'PC2'],\n",
    "    index=df_imputed.index\n",
    ").reset_index()\n",
    "\n",
    "df_scores_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung: Gemeinden im 2D-Raum\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    df_scores_2['PC1'], \n",
    "    df_scores_2['PC2'],\n",
    "    alpha=0.5,\n",
    "    s=20,\n",
    "    c='steelblue'\n",
    ")\n",
    "\n",
    "ax.axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "ax.axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "ax.set_xlabel(f'PC1 ({pca_2.explained_variance_ratio_[0]*100:.1f}%)', fontsize=12)\n",
    "ax.set_ylabel(f'PC2 ({pca_2.explained_variance_ratio_[1]*100:.1f}%)', fontsize=12)\n",
    "ax.set_title('Schweizer Gemeinden im politischen Raum (2 Dimensionen)', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_2d_scatter.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadings für 2-Faktor-Lösung\n",
    "loadings_2 = pd.DataFrame(\n",
    "    pca_2.components_.T,\n",
    "    columns=['PC1', 'PC2'],\n",
    "    index=df_imputed.columns\n",
    ")\n",
    "\n",
    "# Vorlage-Titel hinzufügen\n",
    "proposal_titles = pd.read_sql_query(\n",
    "    \"SELECT proposal_id, title_de, voting_date FROM proposals p JOIN votings v ON p.voting_id = v.voting_id\",\n",
    "    conn\n",
    ")\n",
    "proposal_titles = proposal_titles.set_index('proposal_id')\n",
    "\n",
    "loadings_2['title'] = loadings_2.index.map(lambda x: proposal_titles.loc[x, 'title_de'] if x in proposal_titles.index else 'Unknown')\n",
    "loadings_2['date'] = loadings_2.index.map(lambda x: proposal_titles.loc[x, 'voting_date'] if x in proposal_titles.index else 'Unknown')\n",
    "\n",
    "print(\"Top 10 Vorlagen mit höchster positiver Ladung auf PC1 (Links-Rechts?):\")\n",
    "print(loadings_2.nlargest(10, 'PC1')[['PC1', 'title', 'date']])\n",
    "\n",
    "print(\"\\nTop 10 Vorlagen mit höchster negativer Ladung auf PC1:\")\n",
    "print(loadings_2.nsmallest(10, 'PC1')[['PC1', 'title', 'date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top 10 Vorlagen mit höchster positiver Ladung auf PC2 (Konservativ-Liberal?):\")\n",
    "print(loadings_2.nlargest(10, 'PC2')[['PC2', 'title', 'date']])\n",
    "\n",
    "print(\"\\nTop 10 Vorlagen mit höchster negativer Ladung auf PC2:\")\n",
    "print(loadings_2.nsmallest(10, 'PC2')[['PC2', 'title', 'date']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. PCA mit 3 Faktoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA mit 3 Komponenten\n",
    "pca_3 = PCA(n_components=3)\n",
    "scores_3 = pca_3.fit_transform(X_scaled)\n",
    "\n",
    "print(f\"PCA mit 3 Faktoren:\")\n",
    "print(f\"  Erklärte Varianz PC1: {pca_3.explained_variance_ratio_[0]*100:.2f}%\")\n",
    "print(f\"  Erklärte Varianz PC2: {pca_3.explained_variance_ratio_[1]*100:.2f}%\")\n",
    "print(f\"  Erklärte Varianz PC3: {pca_3.explained_variance_ratio_[2]*100:.2f}%\")\n",
    "print(f\"  Total: {pca_3.explained_variance_ratio_.sum()*100:.2f}%\")\n",
    "\n",
    "# Scores DataFrame\n",
    "df_scores_3 = pd.DataFrame(\n",
    "    scores_3,\n",
    "    columns=['PC1', 'PC2', 'PC3'],\n",
    "    index=df_imputed.index\n",
    ").reset_index()\n",
    "\n",
    "df_scores_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadings für 3-Faktor-Lösung\n",
    "loadings_3 = pd.DataFrame(\n",
    "    pca_3.components_.T,\n",
    "    columns=['PC1', 'PC2', 'PC3'],\n",
    "    index=df_imputed.columns\n",
    ")\n",
    "\n",
    "loadings_3['title'] = loadings_3.index.map(lambda x: proposal_titles.loc[x, 'title_de'] if x in proposal_titles.index else 'Unknown')\n",
    "loadings_3['date'] = loadings_3.index.map(lambda x: proposal_titles.loc[x, 'voting_date'] if x in proposal_titles.index else 'Unknown')\n",
    "\n",
    "print(\"Top 10 Vorlagen mit höchster positiver Ladung auf PC3 (Technokratisch-Ökologisch?):\")\n",
    "print(loadings_3.nlargest(10, 'PC3')[['PC3', 'title', 'date']])\n",
    "\n",
    "print(\"\\nTop 10 Vorlagen mit höchster negativer Ladung auf PC3:\")\n",
    "print(loadings_3.nsmallest(10, 'PC3')[['PC3', 'title', 'date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 3D-Visualisierung\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(14, 10))\nax = fig.add_subplot(111, projection='3d')\n\nscatter = ax.scatter(\n    df_scores_3['PC1'],\n    df_scores_3['PC2'],\n    df_scores_3['PC3'],\n    alpha=0.5,\n    s=15,\n    c='steelblue'\n)\n\nax.set_xlabel(f'PC1: Liberal ← → Konservativ ({pca_3.explained_variance_ratio_[0]*100:.1f}%)')\nax.set_ylabel(f'PC2: Populistisch ← → Establishment ({pca_3.explained_variance_ratio_[1]*100:.1f}%)')\nax.set_zlabel(f'PC3: Technokr. ← → Ökolog. ({pca_3.explained_variance_ratio_[2]*100:.1f}%)')\nax.set_title('Schweizer Gemeinden im politischen Raum (3 Dimensionen)', fontsize=14)\n\nplt.tight_layout()\nplt.savefig('pca_3d_scatter.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Paarweise 2D-Plots für alle drei Dimensionen\nfig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n# PC1 vs PC2\naxes[0].scatter(df_scores_3['PC1'], df_scores_3['PC2'], alpha=0.4, s=15, c='steelblue')\naxes[0].axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\naxes[0].axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\naxes[0].set_xlabel(f'PC1: Liberal ← → Konservativ ({pca_3.explained_variance_ratio_[0]*100:.1f}%)')\naxes[0].set_ylabel(f'PC2: Populistisch ← → Establishment ({pca_3.explained_variance_ratio_[1]*100:.1f}%)')\naxes[0].set_title('Gesellschaftlich vs Establishment')\n\n# PC1 vs PC3\naxes[1].scatter(df_scores_3['PC1'], df_scores_3['PC3'], alpha=0.4, s=15, c='steelblue')\naxes[1].axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\naxes[1].axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\naxes[1].set_xlabel(f'PC1: Liberal ← → Konservativ ({pca_3.explained_variance_ratio_[0]*100:.1f}%)')\naxes[1].set_ylabel(f'PC3: Technokr. ← → Ökolog. ({pca_3.explained_variance_ratio_[2]*100:.1f}%)')\naxes[1].set_title('Gesellschaftlich vs Ökologie')\n\n# PC2 vs PC3\naxes[2].scatter(df_scores_3['PC2'], df_scores_3['PC3'], alpha=0.4, s=15, c='steelblue')\naxes[2].axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\naxes[2].axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\naxes[2].set_xlabel(f'PC2: Populistisch ← → Establishment ({pca_3.explained_variance_ratio_[1]*100:.1f}%)')\naxes[2].set_ylabel(f'PC3: Technokr. ← → Ökolog. ({pca_3.explained_variance_ratio_[2]*100:.1f}%)')\naxes[2].set_title('Establishment vs Ökologie')\n\nplt.tight_layout()\nplt.savefig('pca_3_pairwise.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interpretation der Achsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biplot für die ersten zwei Dimensionen (mit ausgewählten Vorlagen)\n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "\n",
    "# Scores plotten (Gemeinden)\n",
    "ax.scatter(df_scores_2['PC1'], df_scores_2['PC2'], alpha=0.3, s=10, c='lightgray', label='Gemeinden')\n",
    "\n",
    "# Loadings als Vektoren (nur die extremsten)\n",
    "n_arrows = 15\n",
    "\n",
    "# Kombinierte Extremwerte finden\n",
    "loadings_2['importance'] = np.sqrt(loadings_2['PC1']**2 + loadings_2['PC2']**2)\n",
    "top_loadings = loadings_2.nlargest(n_arrows, 'importance')\n",
    "\n",
    "# Skalierungsfaktor für bessere Sichtbarkeit\n",
    "scale = 15\n",
    "\n",
    "for idx, row in top_loadings.iterrows():\n",
    "    ax.arrow(0, 0, row['PC1']*scale, row['PC2']*scale,\n",
    "             head_width=0.3, head_length=0.2, fc='red', ec='red', alpha=0.7)\n",
    "    # Kurztitel für Lesbarkeit\n",
    "    short_title = row['title'][:40] + '...' if len(row['title']) > 40 else row['title']\n",
    "    ax.annotate(short_title, \n",
    "                (row['PC1']*scale*1.1, row['PC2']*scale*1.1),\n",
    "                fontsize=8, alpha=0.8)\n",
    "\n",
    "ax.axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "ax.axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "ax.set_xlabel(f'PC1 ({pca_2.explained_variance_ratio_[0]*100:.1f}%)', fontsize=12)\n",
    "ax.set_ylabel(f'PC2 ({pca_2.explained_variance_ratio_[1]*100:.1f}%)', fontsize=12)\n",
    "ax.set_title('Biplot: Gemeinden und einflussreichste Abstimmungsvorlagen', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('biplot_2d.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Achseninterpretation basierend auf Ladungen\nprint(\"=\"*80)\nprint(\"INTERPRETATION DER POLITISCHEN DIMENSIONEN\")\nprint(\"=\"*80)\n\nprint(\"\\n\" + \"-\"*80)\nprint(\"PC1: LIBERAL ↔ KONSERVATIV (gesellschaftliche Dimension)\")\nprint(\"-\"*80)\nprint(\"\\nLIBERALER Pol (hohe PC1) - Städte wie Zürich, Genf, Lausanne:\")\nfor idx, row in loadings_3.nlargest(5, 'PC1').iterrows():\n    print(f\"  {row['PC1']:+.3f}  {row['date']} - {row['title'][:60]}\")\n\nprint(\"\\nKONSERVATIVER Pol (tiefe PC1) - Innerschweiz wie Muotathal:\")\nfor idx, row in loadings_3.nsmallest(5, 'PC1').iterrows():\n    print(f\"  {row['PC1']:+.3f}  {row['date']} - {row['title'][:60]}\")\n\nprint(\"\\n\" + \"-\"*80)\nprint(\"PC2: ESTABLISHMENT ↔ POPULISTISCH\")\nprint(\"-\"*80)\nprint(\"\\nESTABLISHMENT Pol (hohe PC2) - Goldküste folgt Bundesrat:\")\nfor idx, row in loadings_3.nlargest(5, 'PC2').iterrows():\n    print(f\"  {row['PC2']:+.3f}  {row['date']} - {row['title'][:60]}\")\n\nprint(\"\\nPOPULISTISCHER Pol (tiefe PC2) - gegen Regierungsvorlagen:\")\nfor idx, row in loadings_3.nsmallest(5, 'PC2').iterrows():\n    print(f\"  {row['PC2']:+.3f}  {row['date']} - {row['title'][:60]}\")\n\nprint(\"\\n\" + \"-\"*80)\nprint(\"PC3: ÖKOLOGISCH ↔ TECHNOKRATISCH\")\nprint(\"-\"*80)\nprint(\"\\nÖKOLOGISCHER Pol (hohe PC3) - Städte:\")\nfor idx, row in loadings_3.nlargest(5, 'PC3').iterrows():\n    print(f\"  {row['PC3']:+.3f}  {row['date']} - {row['title'][:60]}\")\n\nprint(\"\\nTECHNOKRATISCHER Pol (tiefe PC3):\")\nfor idx, row in loadings_3.nsmallest(5, 'PC3').iterrows():\n    print(f\"  {row['PC3']:+.3f}  {row['date']} - {row['title'][:60]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extreme Gemeinden identifizieren\nprint(\"=\"*80)\nprint(\"EXTREME GEMEINDEN IN DEN POLITISCHEN DIMENSIONEN\")\nprint(\"=\"*80)\n\nprint(\"\\n\" + \"-\"*60)\nprint(\"PC1: Am LIBERALSTEN (gesellschaftlich offen):\")\nprint(\"-\"*60)\nfor idx, row in df_scores_3.nlargest(5, 'PC1').iterrows():\n    print(f\"  {row['PC1']:+.2f}  {row['municipality_name']}\")\n\nprint(\"\\nPC1: Am KONSERVATIVSTEN (gesellschaftlich traditionell):\")\nfor idx, row in df_scores_3.nsmallest(5, 'PC1').iterrows():\n    print(f\"  {row['PC1']:+.2f}  {row['municipality_name']}\")\n\nprint(\"\\n\" + \"-\"*60)\nprint(\"PC2: Am meisten ESTABLISHMENT (folgt Bundesrat):\")\nprint(\"-\"*60)\nfor idx, row in df_scores_3.nlargest(5, 'PC2').iterrows():\n    print(f\"  {row['PC2']:+.2f}  {row['municipality_name']}\")\n\nprint(\"\\nPC2: Am meisten POPULISTISCH (gegen Regierungsvorlagen):\")\nfor idx, row in df_scores_3.nsmallest(5, 'PC2').iterrows():\n    print(f\"  {row['PC2']:+.2f}  {row['municipality_name']}\")\n\nprint(\"\\n\" + \"-\"*60)\nprint(\"PC3: Am ÖKOLOGISCHSTEN:\")\nprint(\"-\"*60)\nfor idx, row in df_scores_3.nlargest(5, 'PC3').iterrows():\n    print(f\"  {row['PC3']:+.2f}  {row['municipality_name']}\")\n\nprint(\"\\nPC3: Am TECHNOKRATISCHSTEN:\")\nfor idx, row in df_scores_3.nsmallest(5, 'PC3').iterrows():\n    print(f\"  {row['PC3']:+.2f}  {row['municipality_name']}\")\n\n# Bekannte Referenzgemeinden\nprint(\"\\n\" + \"=\"*80)\nprint(\"REFERENZGEMEINDEN ZUR ORIENTIERUNG\")\nprint(\"=\"*80)\nref_cities = ['Zürich', 'Zumikon', 'Muotathal', 'Genève', 'Bern', 'Schwyz']\nfor city in ref_cities:\n    match = df_scores_3[df_scores_3['municipality_name'].str.contains(city, case=False, na=False)]\n    if len(match) > 0:\n        r = match.iloc[0]\n        lib = \"liberal\" if r['PC1'] > 0 else \"konservativ\"\n        est = \"establishment\" if r['PC2'] > 0 else \"populistisch\"\n        oeko = \"ökolog.\" if r['PC3'] > 0 else \"technokr.\"\n        print(f\"  {r['municipality_name']:<20} PC1={r['PC1']:+6.1f} PC2={r['PC2']:+6.1f} PC3={r['PC3']:+6.1f}  → {lib}, {est}, {oeko}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Faktorrotation (Varimax) für bessere Interpretierbarkeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import special_ortho_group\n",
    "from scipy.linalg import svd\n",
    "\n",
    "def varimax_rotation(loadings, max_iter=100, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Varimax-Rotation für bessere Interpretierbarkeit der Faktoren.\n",
    "    \"\"\"\n",
    "    n_vars, n_factors = loadings.shape\n",
    "    rotation_matrix = np.eye(n_factors)\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        old_rotation = rotation_matrix.copy()\n",
    "        \n",
    "        # Rotierte Ladungen\n",
    "        rotated = loadings @ rotation_matrix\n",
    "        \n",
    "        # Varimax-Kriterium maximieren\n",
    "        tmp = rotated ** 3 - rotated * (rotated ** 2).sum(axis=0) / n_vars\n",
    "        u, s, vh = svd(loadings.T @ tmp)\n",
    "        rotation_matrix = u @ vh\n",
    "        \n",
    "        # Konvergenzprüfung\n",
    "        if np.max(np.abs(rotation_matrix - old_rotation)) < tol:\n",
    "            break\n",
    "    \n",
    "    return loadings @ rotation_matrix, rotation_matrix\n",
    "\n",
    "# Varimax auf 3-Faktor-Lösung anwenden\n",
    "loadings_raw = pca_3.components_.T\n",
    "loadings_rotated, rotation_matrix = varimax_rotation(loadings_raw)\n",
    "\n",
    "print(\"Varimax-Rotation durchgeführt.\")\n",
    "print(f\"\\nRotationsmatrix:\\n{rotation_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotierte Ladungen analysieren\n",
    "loadings_rot_df = pd.DataFrame(\n",
    "    loadings_rotated,\n",
    "    columns=['RC1', 'RC2', 'RC3'],\n",
    "    index=df_imputed.columns\n",
    ")\n",
    "\n",
    "loadings_rot_df['title'] = loadings_rot_df.index.map(lambda x: proposal_titles.loc[x, 'title_de'] if x in proposal_titles.index else 'Unknown')\n",
    "loadings_rot_df['date'] = loadings_rot_df.index.map(lambda x: proposal_titles.loc[x, 'voting_date'] if x in proposal_titles.index else 'Unknown')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ROTIERTE FAKTOREN (VARIMAX)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for rc in ['RC1', 'RC2', 'RC3']:\n",
    "    print(f\"\\n{'-'*60}\")\n",
    "    print(f\"{rc}: Top 5 positive Ladungen\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    for idx, row in loadings_rot_df.nlargest(5, rc).iterrows():\n",
    "        print(f\"  {row[rc]:.3f}  {row['date']} - {row['title'][:55]}\")\n",
    "    \n",
    "    print(f\"\\n{rc}: Top 5 negative Ladungen\")\n",
    "    for idx, row in loadings_rot_df.nsmallest(5, rc).iterrows():\n",
    "        print(f\"  {row[rc]:.3f}  {row['date']} - {row['title'][:55]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotierte Scores berechnen\n",
    "scores_rotated = scores_3 @ rotation_matrix\n",
    "\n",
    "df_scores_rot = pd.DataFrame(\n",
    "    scores_rotated,\n",
    "    columns=['RC1', 'RC2', 'RC3'],\n",
    "    index=df_imputed.index\n",
    ").reset_index()\n",
    "\n",
    "# Paarweise Plots der rotierten Faktoren\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# RC1 vs RC2\n",
    "axes[0].scatter(df_scores_rot['RC1'], df_scores_rot['RC2'], alpha=0.4, s=15, c='steelblue')\n",
    "axes[0].axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "axes[0].axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "axes[0].set_xlabel('RC1')\n",
    "axes[0].set_ylabel('RC2')\n",
    "axes[0].set_title('RC1 vs RC2 (Varimax-rotiert)')\n",
    "\n",
    "# RC1 vs RC3\n",
    "axes[1].scatter(df_scores_rot['RC1'], df_scores_rot['RC3'], alpha=0.4, s=15, c='steelblue')\n",
    "axes[1].axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "axes[1].axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "axes[1].set_xlabel('RC1')\n",
    "axes[1].set_ylabel('RC3')\n",
    "axes[1].set_title('RC1 vs RC3 (Varimax-rotiert)')\n",
    "\n",
    "# RC2 vs RC3\n",
    "axes[2].scatter(df_scores_rot['RC2'], df_scores_rot['RC3'], alpha=0.4, s=15, c='steelblue')\n",
    "axes[2].axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "axes[2].axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "axes[2].set_xlabel('RC2')\n",
    "axes[2].set_ylabel('RC3')\n",
    "axes[2].set_title('RC2 vs RC3 (Varimax-rotiert)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('pca_3_varimax_rotated.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores exportieren für weitere Analysen\n",
    "df_scores_3.to_csv('municipality_pca_scores_3factors.csv', index=False)\n",
    "df_scores_rot.to_csv('municipality_pca_scores_3factors_rotated.csv', index=False)\n",
    "\n",
    "# Loadings exportieren\n",
    "loadings_3.to_csv('proposal_loadings_3factors.csv')\n",
    "loadings_rot_df.to_csv('proposal_loadings_3factors_rotated.csv')\n",
    "\n",
    "print(\"Ergebnisse exportiert:\")\n",
    "print(\"  - municipality_pca_scores_3factors.csv\")\n",
    "print(\"  - municipality_pca_scores_3factors_rotated.csv\")\n",
    "print(\"  - proposal_loadings_3factors.csv\")\n",
    "print(\"  - proposal_loadings_3factors_rotated.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Zusammenfassung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*80)\nprint(\"ZUSAMMENFASSUNG DER PCA-ANALYSE\")\nprint(\"=\"*80)\n\nprint(f\"\\nDatenbasis:\")\nprint(f\"  - {df_imputed.shape[0]} Gemeinden\")\nprint(f\"  - {df_imputed.shape[1]} Abstimmungsvorlagen\")\nprint(f\"  - Zeitraum: 2000-2025\")\n\nprint(f\"\\nFaktorenanalyse:\")\nprint(f\"  - Kaiser-Kriterium empfiehlt: {n_kaiser} Faktoren\")\nprint(f\"  - Literatur empfiehlt: 2-3 Faktoren\")\n\nprint(f\"\\nErklärte Varianz (3 Faktoren):\")\nprint(f\"  - PC1: {pca_3.explained_variance_ratio_[0]*100:.1f}%\")\nprint(f\"  - PC2: {pca_3.explained_variance_ratio_[1]*100:.1f}%\")\nprint(f\"  - PC3: {pca_3.explained_variance_ratio_[2]*100:.1f}%\")\nprint(f\"  - Total: {pca_3.explained_variance_ratio_.sum()*100:.1f}%\")\n\nprint(f\"\\nInterpretation der Dimensionen:\")\nprint(f\"  - PC1: Liberal ↔ Konservativ (gesellschaftlich)\")\nprint(f\"         Vorlagen: Einbürgerung, EU, Ausländerpolitik\")\nprint(f\"         Liberal: Zürich, Genf, Lausanne | Konservativ: Muotathal, Unteriberg\")\nprint(f\"\")\nprint(f\"  - PC2: Establishment ↔ Populistisch\")\nprint(f\"         Vorlagen: AHV-Reformen, Regierungsvorlagen vs. populistische Initiativen\")\nprint(f\"         Establishment: Zumikon, Küsnacht | Populistisch: Innerschweiz, Berner Jura\")\nprint(f\"         HINWEIS: Nicht identisch mit Links-Rechts!\")\nprint(f\"\")\nprint(f\"  - PC3: Ökologisch ↔ Technokratisch\")\nprint(f\"         Vorlagen: Umwelt, Energie, Pestizide\")\nprint(f\"         Ökologisch: Bern, Basel, Zürich | Technokratisch: ländliche Gemeinden\")\n\nprint(f\"\\nBefund:\")\nprint(f\"  Die Analyse findet 2 starke + 1 schwächere Dimension.\")\nprint(f\"  Die wirtschaftliche Links-Rechts-Dimension ist in PC2 mit\")\nprint(f\"  Establishment/Populismus-Aspekten vermischt.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenbankverbindung schliessen\n",
    "conn.close()\n",
    "print(\"Datenbankverbindung geschlossen.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}