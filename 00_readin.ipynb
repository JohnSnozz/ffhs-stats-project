{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swiss Voting Data Aggregation\n",
    "\n",
    "This notebook reads all individual Swiss federal voting JSON files and combines them into a single comprehensive JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_dir = Path('data/votes')\n",
    "output_file = Path('data/all_votings_combined.json')\n",
    "\n",
    "# Pattern for voting files\n",
    "file_pattern = 'sd-t-17-02-*-eidgAbstimmung.json'\n",
    "\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Output file: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all voting JSON files\n",
    "voting_files = sorted(data_dir.glob(file_pattern))\n",
    "print(f\"Found {len(voting_files)} voting files\")\n",
    "\n",
    "# Display first few files\n",
    "print(\"\\nFirst 5 files:\")\n",
    "for file in voting_files[:5]:\n",
    "    print(f\"  - {file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize container for all votings\n",
    "all_votings = {\n",
    "    \"metadata\": {\n",
    "        \"created_at\": datetime.now().isoformat(),\n",
    "        \"source_files_count\": len(voting_files),\n",
    "        \"description\": \"Combined Swiss federal voting data from 2000-2025\",\n",
    "        \"note\": \"Geographic structures (Gemeinde, Bezirke, Kantone) have changed over time\"\n",
    "    },\n",
    "    \"votings\": []\n",
    "}\n",
    "\n",
    "print(\"Initialized data structure for combined votings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process each voting file\n",
    "errors = []\n",
    "successful_reads = 0\n",
    "\n",
    "for idx, file_path in enumerate(voting_files, 1):\n",
    "    try:\n",
    "        # Extract date from filename\n",
    "        filename = file_path.name\n",
    "        date_str = filename.split('-')[5].replace('eidgAbstimmung.json', '')\n",
    "        \n",
    "        # Read JSON file\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            voting_data = json.load(f)\n",
    "        \n",
    "        # Add source filename to the data\n",
    "        voting_data['source_file'] = filename\n",
    "        \n",
    "        # Add to combined structure\n",
    "        all_votings['votings'].append(voting_data)\n",
    "        \n",
    "        successful_reads += 1\n",
    "        \n",
    "        # Progress indicator\n",
    "        if idx % 10 == 0:\n",
    "            print(f\"Processed {idx}/{len(voting_files)} files...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error reading {filename}: {str(e)}\"\n",
    "        errors.append(error_msg)\n",
    "        print(f\"  ⚠ {error_msg}\")\n",
    "\n",
    "print(f\"\\n✓ Successfully read {successful_reads}/{len(voting_files)} files\")\n",
    "if errors:\n",
    "    print(f\"⚠ Encountered {len(errors)} errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort votings by date\n",
    "all_votings['votings'] = sorted(all_votings['votings'], key=lambda x: x.get('abstimmtag', ''))\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(f\"- Total votings: {len(all_votings['votings'])}\")\n",
    "\n",
    "if all_votings['votings']:\n",
    "    print(f\"- Date range: {all_votings['votings'][0].get('abstimmtag', 'N/A')} to {all_votings['votings'][-1].get('abstimmtag', 'N/A')}\")\n",
    "    \n",
    "    # Count unique spatial reference dates\n",
    "    spatial_dates = set()\n",
    "    for voting in all_votings['votings']:\n",
    "        if 'spatial_reference' in voting:\n",
    "            for ref in voting['spatial_reference']:\n",
    "                spatial_dates.add((ref.get('spatial_unit'), ref.get('spatial_date')))\n",
    "    \n",
    "    print(f\"- Unique spatial reference combinations: {len(spatial_dates)}\")\n",
    "    print(\"\\nSpatial units found:\")\n",
    "    for unit, date in sorted(spatial_dates):\n",
    "        print(f\"  - {unit}: {date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined data to JSON file\n",
    "print(f\"\\nSaving combined data to {output_file}...\")\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_votings, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Check file size\n",
    "    file_size_mb = output_file.stat().st_size / (1024 * 1024)\n",
    "    print(f\"✓ Successfully saved combined JSON file\")\n",
    "    print(f\"  File size: {file_size_mb:.2f} MB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error saving file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation: Read back and verify\n",
    "print(\"\\nValidating saved file...\")\n",
    "\n",
    "try:\n",
    "    with open(output_file, 'r', encoding='utf-8') as f:\n",
    "        validation_data = json.load(f)\n",
    "    \n",
    "    print(f\"✓ File is valid JSON\")\n",
    "    print(f\"  Contains {len(validation_data['votings'])} voting records\")\n",
    "    print(f\"  Metadata: {validation_data['metadata']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Validation failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample structure of first voting\n",
    "if all_votings['votings']:\n",
    "    print(\"\\nSample structure of first voting record:\")\n",
    "    first_voting = all_votings['votings'][0]\n",
    "    \n",
    "    def print_structure(obj, indent=0):\n",
    "        \"\"\"Recursively print JSON structure with data types\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            for key in list(obj.keys())[:5]:  # Show first 5 keys\n",
    "                value = obj[key]\n",
    "                if isinstance(value, (dict, list)):\n",
    "                    print(\" \" * indent + f\"{key}: {type(value).__name__}\")\n",
    "                    if indent < 6:  # Limit recursion depth\n",
    "                        print_structure(value, indent + 2)\n",
    "                else:\n",
    "                    print(\" \" * indent + f\"{key}: {type(value).__name__} = {str(value)[:50]}...\" if len(str(value)) > 50 else f\"{key}: {type(value).__name__} = {value}\")\n",
    "        elif isinstance(obj, list) and obj:\n",
    "            print(\" \" * indent + f\"[List with {len(obj)} items]\")\n",
    "            if indent < 6:  # Limit recursion depth\n",
    "                print_structure(obj[0], indent + 2)\n",
    "    \n",
    "    print_structure(first_voting)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Display the structure in a readable format\nprint(\"\\n\" + \"=\"*50)\nprint(\"JSON STRUCTURE (for LLM understanding):\")\nprint(\"=\"*50 + \"\\n\")\nprint(json.dumps(structure, indent=2, ensure_ascii=False)[:2000] + \"...\\n[truncated for display]\")\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"IMPORTANT NOTES:\")\nprint(\"=\"*50)\nprint(\"1. Full data file size: 300+ MB (all_votings_combined.json)\")\nprint(\"2. Structure file size: < 50 KB (voting_structure.json)\")\nprint(\"3. ⚠️  ALWAYS use the structure files for LLM analysis, NOT the full data file!\")\nprint(\"4. Files created:\")\nprint(\"   - data/all_votings_combined.json (300+ MB) - Full data\")\nprint(\"   - data/voting_structure.json (~KB) - JSON structure for LLMs\")\nprint(\"   - data/voting_structure_documentation.md (~KB) - Human-readable documentation\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Also create a human-readable structure documentation\nstructure_doc_file = Path('data/voting_structure_documentation.md')\n\ndef generate_markdown_doc(structure, indent_level=0):\n    \"\"\"Generate a markdown documentation of the JSON structure\"\"\"\n    lines = []\n    indent = \"  \" * indent_level\n    \n    if isinstance(structure, dict):\n        # Check if it's an array description\n        if \"_type\" in structure and structure[\"_type\"] == \"array\":\n            lines.append(f\"{indent}- **Array** ({structure.get('_count', 'unknown')} items)\")\n            if \"_sample\" in structure:\n                lines.append(f\"{indent}  Sample item structure:\")\n                lines.extend(generate_markdown_doc(structure[\"_sample\"], indent_level + 2))\n            elif \"_samples\" in structure:\n                lines.append(f\"{indent}  Note: {structure.get('_note', '')}\")\n                for i, sample in enumerate(structure[\"_samples\"]):\n                    lines.append(f\"{indent}  Sample {i+1}:\")\n                    lines.extend(generate_markdown_doc(sample, indent_level + 2))\n        else:\n            # Regular dictionary\n            for key, value in structure.items():\n                if isinstance(value, dict):\n                    lines.append(f\"{indent}- **{key}**: Object\")\n                    lines.extend(generate_markdown_doc(value, indent_level + 1))\n                elif isinstance(value, str):\n                    lines.append(f\"{indent}- **{key}**: {value}\")\n                else:\n                    lines.append(f\"{indent}- **{key}**: {str(value)}\")\n    else:\n        lines.append(f\"{indent}- {structure}\")\n    \n    return lines\n\n# Generate documentation\ndoc_content = [\n    \"# Swiss Voting Data Structure Documentation\",\n    \"\",\n    \"This document describes the structure of the combined Swiss voting JSON data.\",\n    \"The actual data file is 300+ MB, but this structure document helps understand the schema.\",\n    \"\",\n    \"## Data Structure\",\n    \"\"\n]\n\ndoc_content.extend(generate_markdown_doc(structure))\n\ndoc_content.extend([\n    \"\",\n    \"## Notes\",\n    \"\",\n    \"- The full dataset (`all_votings_combined.json`) is over 300 MB\",\n    \"- Use this structure file (`voting_structure.json`) for LLM analysis instead of the full file\",\n    \"- Geographic structures (Gemeinde, Bezirke, Kantone) have changed over time (2000-2025)\",\n    \"- Each voting contains nested hierarchical data: Switzerland → Cantons → Districts → Municipalities\",\n    \"\"\n])\n\ntry:\n    with open(structure_doc_file, 'w', encoding='utf-8') as f:\n        f.write(\"\\\\n\".join(doc_content))\n    \n    print(f\"✓ Structure documentation saved to {structure_doc_file}\")\n    print(f\"  File size: {structure_doc_file.stat().st_size / 1024:.2f} KB\")\n    \nexcept Exception as e:\n    print(f\"✗ Error saving documentation: {str(e)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Save the structure to a JSON file\nstructure_file = Path('data/voting_structure.json')\n\ntry:\n    with open(structure_file, 'w', encoding='utf-8') as f:\n        json.dump(structure, f, ensure_ascii=False, indent=2)\n    \n    # Check file size\n    file_size_kb = structure_file.stat().st_size / 1024\n    print(f\"✓ Structure saved to {structure_file}\")\n    print(f\"  File size: {file_size_kb:.2f} KB (vs {output_file.stat().st_size / (1024*1024):.2f} MB for full data)\")\n    \nexcept Exception as e:\n    print(f\"✗ Error saving structure file: {str(e)}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def extract_structure(obj, max_array_sample=2, depth=0, max_depth=10):\n    \"\"\"\n    Extract the structure/schema of a JSON object.\n    For arrays, only samples the first few items to keep size small.\n    \"\"\"\n    if depth > max_depth:\n        return \"...[max depth reached]\"\n    \n    if isinstance(obj, dict):\n        structure = {}\n        for key, value in obj.items():\n            structure[key] = extract_structure(value, max_array_sample, depth + 1, max_depth)\n        return structure\n    \n    elif isinstance(obj, list):\n        if not obj:\n            return \"[]\"\n        \n        # For lists, sample only first few items and detect if all items have same structure\n        sample_items = obj[:min(max_array_sample, len(obj))]\n        structures = [extract_structure(item, max_array_sample, depth + 1, max_depth) for item in sample_items]\n        \n        # Check if all sampled items have the same structure\n        if len(set(str(s) for s in structures)) == 1:\n            # All items have same structure\n            return {\n                \"_type\": \"array\",\n                \"_count\": len(obj),\n                \"_sample\": structures[0]\n            }\n        else:\n            # Different structures\n            return {\n                \"_type\": \"array\",\n                \"_count\": len(obj),\n                \"_samples\": structures,\n                \"_note\": \"Items have varying structures\"\n            }\n    \n    elif isinstance(obj, str):\n        # Return type and a sample value (truncated if long)\n        if len(obj) > 50:\n            return f\"string (sample: '{obj[:47]}...')\"\n        return f\"string ('{obj}')\"\n    \n    elif isinstance(obj, (int, float)):\n        return f\"{type(obj).__name__} ({obj})\"\n    \n    elif isinstance(obj, bool):\n        return f\"boolean ({obj})\"\n    \n    elif obj is None:\n        return \"null\"\n    \n    else:\n        return f\"{type(obj).__name__}\"\n\n# Extract structure from the combined data\nprint(\"Extracting JSON structure...\")\nif all_votings and all_votings.get('votings'):\n    structure = extract_structure(all_votings, max_array_sample=1)\n    print(\"✓ Structure extracted successfully\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Extract JSON Schema/Structure\n\nThe following cells create a schema file that describes the structure of the JSON data. This schema file is much smaller than the actual data (KB instead of 300+ MB) and can be used by LLMs to understand the data structure without loading the entire dataset.",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}