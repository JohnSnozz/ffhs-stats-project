{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression: Abstimmungsverhalten\n",
    "\n",
    "Analyse des Abstimmungsverhaltens (Ja/Nein) basierend auf Gemeindemerkmalen.\n",
    "\n",
    "**Outcome:** Binaer - Hat die Gemeinde mehrheitlich Ja gestimmt? (ja_prozent > 50)\n",
    "\n",
    "**Praediktoren:** Kategoriale Gemeindemerkmale (Sprachgebiet, Stadt/Land, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc\n",
    "import statsmodels.api as sm\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "DB_PATH = Path('../../data/processed/swiss_votings.db')\n",
    "OUTPUT_DIR = Path('output')\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Seaborn style\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(f\"Database: {DB_PATH}\")\n",
    "print(f\"Output: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Daten laden und vorbereiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# Load voting results with features (only municipalities with matching features)\n",
    "df = pd.read_sql_query(\"\"\"\n",
    "    SELECT \n",
    "        vr.proposal_id,\n",
    "        vr.voting_date,\n",
    "        vr.title_de,\n",
    "        vr.municipality_id,\n",
    "        vr.municipality_name,\n",
    "        vr.ja_prozent,\n",
    "        vr.angenommen,\n",
    "        mf.sprachgebiete,\n",
    "        mf.stadt_land_typologie,\n",
    "        mf.grossregionen_der_schweiz,\n",
    "        mf.urbanisierungsgrad_degurba_eurostat,\n",
    "        mf.berggebiete,\n",
    "        mf.agglomerationsgroessenklasse,\n",
    "        mf.gemeindetypologie_9_typen\n",
    "    FROM v_voting_results_analysis vr\n",
    "    INNER JOIN municipality_features_2024 mf ON vr.municipality_id = mf.bfs_nr\n",
    "    WHERE vr.municipality_id < 9000\n",
    "    ORDER BY vr.voting_date, vr.proposal_id\n",
    "\"\"\", conn)\n",
    "\n",
    "# Load feature labels\n",
    "labels_df = pd.read_sql_query(\"SELECT * FROM feature_labels_2024\", conn)\n",
    "conn.close()\n",
    "\n",
    "# Create binary outcome\n",
    "df['ja_mehrheit'] = (df['ja_prozent'] > 50).astype(int)\n",
    "\n",
    "print(f\"Datensaetze: {len(df):,}\")\n",
    "print(f\"Abstimmungen: {df['proposal_id'].nunique()}\")\n",
    "print(f\"Gemeinden: {df['municipality_id'].nunique()}\")\n",
    "print(f\"\\nJa-Mehrheit: {df['ja_mehrheit'].sum():,} ({100*df['ja_mehrheit'].mean():.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique proposals\n",
    "proposals = df.groupby('proposal_id').agg({\n",
    "    'voting_date': 'first',\n",
    "    'title_de': 'first',\n",
    "    'angenommen': 'first',\n",
    "    'ja_prozent': 'mean'\n",
    "}).reset_index()\n",
    "proposals = proposals.sort_values('voting_date').reset_index(drop=True)\n",
    "proposals.columns = ['proposal_id', 'voting_date', 'title_de', 'angenommen', 'mean_ja']\n",
    "\n",
    "print(f\"Anzahl Abstimmungen: {len(proposals)}\")\n",
    "proposals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns and create label mappings\n",
    "feature_cols = [\n",
    "    'sprachgebiete',\n",
    "    'stadt_land_typologie', \n",
    "    'grossregionen_der_schweiz',\n",
    "    'urbanisierungsgrad_degurba_eurostat',\n",
    "    'berggebiete',\n",
    "    'agglomerationsgroessenklasse'\n",
    "]\n",
    "\n",
    "# Create label lookup\n",
    "def get_label(feature_name, code):\n",
    "    subset = labels_df[(labels_df['feature_name'] == feature_name) & (labels_df['code'] == code)]\n",
    "    if len(subset) > 0:\n",
    "        return subset['label'].iloc[0]\n",
    "    return str(code)\n",
    "\n",
    "# Nice feature names for display\n",
    "feature_names_display = {\n",
    "    'sprachgebiete': 'Sprachgebiet',\n",
    "    'stadt_land_typologie': 'Stadt/Land',\n",
    "    'grossregionen_der_schweiz': 'Grossregion',\n",
    "    'urbanisierungsgrad_degurba_eurostat': 'Urbanisierung',\n",
    "    'berggebiete': 'Berggebiet',\n",
    "    'agglomerationsgroessenklasse': 'Agglomerationsgroesse'\n",
    "}\n",
    "\n",
    "print(\"Features fuer Regression:\")\n",
    "for col in feature_cols:\n",
    "    n_cat = df[col].nunique()\n",
    "    print(f\"  - {feature_names_display[col]}: {n_cat} Kategorien\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistische Regression pro Abstimmung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def run_logistic_regression(df_vote, feature_cols):\n    \"\"\"\n    Run logistic regression for a single voting.\n    Returns model results and metrics.\n    \"\"\"\n    # Prepare data with dummy encoding\n    X = pd.get_dummies(df_vote[feature_cols], columns=feature_cols, drop_first=True)\n    X = X.astype(float)  # Convert to float for statsmodels\n    y = df_vote['ja_mehrheit'].astype(float)\n    \n    # Check if outcome has variance\n    if y.nunique() < 2:\n        return None, None, \"Keine Varianz im Outcome\"\n    \n    # Statsmodels for detailed results\n    X_sm = sm.add_constant(X)\n    try:\n        model = sm.Logit(y, X_sm).fit(disp=0, maxiter=100)\n    except Exception as e:\n        return None, None, str(e)\n    \n    # Predictions\n    y_pred_prob = model.predict(X_sm)\n    y_pred = (y_pred_prob > 0.5).astype(int)\n    \n    # Metrics\n    accuracy = accuracy_score(y, y_pred)\n    \n    # ROC AUC\n    try:\n        fpr, tpr, _ = roc_curve(y, y_pred_prob)\n        roc_auc = auc(fpr, tpr)\n    except:\n        roc_auc = np.nan\n    \n    metrics = {\n        'accuracy': accuracy,\n        'auc': roc_auc,\n        'pseudo_r2': model.prsquared,\n        'n': len(y),\n        'n_ja': int(y.sum()),\n        'pct_ja': 100 * y.mean()\n    }\n    \n    return model, metrics, None"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run logistic regression for all votings\nresults = []\nmodels = {}\n\nfor _, prop in proposals.iterrows():\n    proposal_id = prop['proposal_id']\n    df_vote = df[df['proposal_id'] == proposal_id].copy()\n    \n    model, metrics, error = run_logistic_regression(df_vote, feature_cols)\n    \n    result = {\n        'proposal_id': proposal_id,\n        'voting_date': prop['voting_date'],\n        'title_de': prop['title_de'],\n        'angenommen': prop['angenommen'],\n        'mean_ja': prop['mean_ja'],\n        'error': error,\n        'accuracy': np.nan,\n        'auc': np.nan,\n        'pseudo_r2': np.nan,\n        'n': np.nan,\n        'n_ja': np.nan,\n        'pct_ja': np.nan\n    }\n    \n    if metrics:\n        result.update(metrics)\n        models[proposal_id] = model\n    \n    results.append(result)\n\nresults_df = pd.DataFrame(results)\nprint(f\"Modelle erfolgreich: {len(models)} / {len(proposals)}\")\nprint(f\"Fehler: {results_df['error'].notna().sum()}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Summary statistics\nsuccessful = results_df[results_df['error'].isna() & results_df['accuracy'].notna()].copy()\n\nprint(\"Modell-Performance (Zusammenfassung):\")\nprint(f\"  Accuracy - Mean: {successful['accuracy'].mean():.3f}, Median: {successful['accuracy'].median():.3f}\")\nprint(f\"  AUC - Mean: {successful['auc'].mean():.3f}, Median: {successful['auc'].median():.3f}\")\nprint(f\"  Pseudo R2 - Mean: {successful['pseudo_r2'].mean():.3f}, Median: {successful['pseudo_r2'].median():.3f}\")\n\n# Save results\nresults_df.to_csv(OUTPUT_DIR / 'logistic_regression_results.csv', index=False)\nprint(f\"\\nResultate gespeichert: {OUTPUT_DIR / 'logistic_regression_results.csv'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualisierungen erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plots directory\n",
    "plots_dir = OUTPUT_DIR / 'plots'\n",
    "plots_dir.mkdir(exist_ok=True)\n",
    "\n",
    "def create_coefficient_plot(model, proposal_id, voting_date, title_de, output_path):\n",
    "    \"\"\"\n",
    "    Create a coefficient plot (odds ratios) for the logistic regression.\n",
    "    \"\"\"\n",
    "    # Extract coefficients (exclude constant)\n",
    "    params = model.params[1:]  # Skip constant\n",
    "    conf_int = model.conf_int().iloc[1:]  # Skip constant\n",
    "    pvalues = model.pvalues[1:]\n",
    "    \n",
    "    # Calculate odds ratios\n",
    "    odds_ratios = np.exp(params)\n",
    "    ci_lower = np.exp(conf_int[0])\n",
    "    ci_upper = np.exp(conf_int[1])\n",
    "    \n",
    "    # Create dataframe for plotting\n",
    "    coef_df = pd.DataFrame({\n",
    "        'feature': params.index,\n",
    "        'odds_ratio': odds_ratios.values,\n",
    "        'ci_lower': ci_lower.values,\n",
    "        'ci_upper': ci_upper.values,\n",
    "        'pvalue': pvalues.values\n",
    "    })\n",
    "    \n",
    "    # Sort by odds ratio\n",
    "    coef_df = coef_df.sort_values('odds_ratio', ascending=True)\n",
    "    \n",
    "    # Limit to top/bottom 15 for readability\n",
    "    if len(coef_df) > 20:\n",
    "        top = coef_df.nlargest(10, 'odds_ratio')\n",
    "        bottom = coef_df.nsmallest(10, 'odds_ratio')\n",
    "        coef_df = pd.concat([bottom, top]).drop_duplicates()\n",
    "        coef_df = coef_df.sort_values('odds_ratio', ascending=True)\n",
    "    \n",
    "    # Create plot\n",
    "    fig_height = max(5, len(coef_df) * 0.35)\n",
    "    fig, ax = plt.subplots(figsize=(10, fig_height))\n",
    "    \n",
    "    # Colors based on significance\n",
    "    colors = ['#27ae60' if p < 0.05 else '#95a5a6' for p in coef_df['pvalue']]\n",
    "    \n",
    "    # Plot odds ratios with confidence intervals\n",
    "    y_pos = range(len(coef_df))\n",
    "    ax.barh(y_pos, coef_df['odds_ratio'] - 1, left=1, color=colors, alpha=0.7, height=0.6)\n",
    "    \n",
    "    # Error bars for CI\n",
    "    ax.errorbar(coef_df['odds_ratio'], y_pos, \n",
    "                xerr=[coef_df['odds_ratio'] - coef_df['ci_lower'], \n",
    "                      coef_df['ci_upper'] - coef_df['odds_ratio']],\n",
    "                fmt='none', color='#2c3e50', capsize=3, capthick=1)\n",
    "    \n",
    "    # Reference line at OR=1\n",
    "    ax.axvline(1, color='#e74c3c', linestyle='--', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # Labels\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(coef_df['feature'], fontsize=9)\n",
    "    ax.set_xlabel('Odds Ratio', fontsize=11)\n",
    "    \n",
    "    # Title (truncated)\n",
    "    title_short = title_de[:60] + '...' if len(title_de) > 60 else title_de\n",
    "    ax.set_title(f'{voting_date}: {title_short}', fontsize=11, fontweight='bold', pad=10)\n",
    "    \n",
    "    # Clean up\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    # Legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#27ae60', alpha=0.7, label='Signifikant (p<0.05)'),\n",
    "        Patch(facecolor='#95a5a6', alpha=0.7, label='Nicht signifikant'),\n",
    "        plt.Line2D([0], [0], color='#e74c3c', linestyle='--', linewidth=2, label='OR = 1 (kein Effekt)')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, dpi=100, facecolor='white', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(\"Erstelle Koeffizienten-Plots...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate plots for all successful models\n",
    "for proposal_id, model in models.items():\n",
    "    prop = proposals[proposals['proposal_id'] == proposal_id].iloc[0]\n",
    "    output_path = plots_dir / f'coef_{proposal_id:03d}.png'\n",
    "    \n",
    "    create_coefficient_plot(\n",
    "        model, \n",
    "        proposal_id,\n",
    "        prop['voting_date'],\n",
    "        prop['title_de'],\n",
    "        output_path\n",
    "    )\n",
    "\n",
    "print(f\"Gespeichert: {len(models)} Koeffizienten-Plots in {plots_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Uebersichtsgrafiken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model performance overview\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "# Accuracy distribution\n",
    "ax1 = axes[0]\n",
    "sns.histplot(successful['accuracy'], bins=20, color='steelblue', edgecolor='white', ax=ax1)\n",
    "ax1.axvline(successful['accuracy'].median(), color='#e74c3c', linestyle='--', linewidth=2,\n",
    "            label=f'Median: {successful[\"accuracy\"].median():.3f}')\n",
    "ax1.set_xlabel('Accuracy')\n",
    "ax1.set_ylabel('Anzahl Abstimmungen')\n",
    "ax1.set_title('Verteilung Accuracy', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "# AUC distribution\n",
    "ax2 = axes[1]\n",
    "sns.histplot(successful['auc'].dropna(), bins=20, color='#27ae60', edgecolor='white', ax=ax2)\n",
    "ax2.axvline(successful['auc'].median(), color='#e74c3c', linestyle='--', linewidth=2,\n",
    "            label=f'Median: {successful[\"auc\"].median():.3f}')\n",
    "ax2.set_xlabel('AUC')\n",
    "ax2.set_ylabel('Anzahl Abstimmungen')\n",
    "ax2.set_title('Verteilung AUC', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "# Pseudo R2 distribution\n",
    "ax3 = axes[2]\n",
    "sns.histplot(successful['pseudo_r2'], bins=20, color='#9b59b6', edgecolor='white', ax=ax3)\n",
    "ax3.axvline(successful['pseudo_r2'].median(), color='#e74c3c', linestyle='--', linewidth=2,\n",
    "            label=f'Median: {successful[\"pseudo_r2\"].median():.3f}')\n",
    "ax3.set_xlabel('McFadden Pseudo R²')\n",
    "ax3.set_ylabel('Anzahl Abstimmungen')\n",
    "ax3.set_title('Verteilung Pseudo R²', fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.spines['top'].set_visible(False)\n",
    "ax3.spines['right'].set_visible(False)\n",
    "\n",
    "plt.suptitle('Modell-Performance: Logistische Regression\\n(alle 223 Abstimmungen)', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / 'model_performance_overview.png', dpi=150, facecolor='white', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Best and worst models\nif successful['auc'].notna().any():\n    print(\"Top 5 Modelle (hoechste AUC):\")\n    top5 = successful.dropna(subset=['auc']).nlargest(5, 'auc')[['voting_date', 'title_de', 'auc', 'pseudo_r2', 'accuracy']]\n    for _, row in top5.iterrows():\n        print(f\"  AUC={row['auc']:.3f}: {row['voting_date']} - {row['title_de'][:50]}...\")\n\n    print(\"\\nBottom 5 Modelle (tiefste AUC):\")\n    bottom5 = successful.dropna(subset=['auc']).nsmallest(5, 'auc')[['voting_date', 'title_de', 'auc', 'pseudo_r2', 'accuracy']]\n    for _, row in bottom5.iterrows():\n        print(f\"  AUC={row['auc']:.3f}: {row['voting_date']} - {row['title_de'][:50]}...\")\nelse:\n    print(\"Keine AUC-Werte verfuegbar.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example: Best model details\nif len(models) > 0 and successful['auc'].notna().any():\n    best_idx = successful['auc'].idxmax()\n    best_id = successful.loc[best_idx, 'proposal_id']\n    best_model = models[best_id]\n    best_prop = proposals[proposals['proposal_id'] == best_id].iloc[0]\n\n    print(f\"Bestes Modell: {best_prop['voting_date']} - {best_prop['title_de'][:60]}...\")\n    print(\"\\nModell-Summary:\")\n    print(best_model.summary())\nelse:\n    print(\"Keine erfolgreichen Modelle vorhanden.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Zusammenfassung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"LOGISTISCHE REGRESSION - ZUSAMMENFASSUNG\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Anzahl Abstimmungen: {len(proposals)}\")\n",
    "print(f\"Erfolgreiche Modelle: {len(models)}\")\n",
    "print(f\"Gemeinden pro Modell: ~{int(successful['n'].mean())}\")\n",
    "print()\n",
    "print(\"Features (Praediktoren):\")\n",
    "for col in feature_cols:\n",
    "    print(f\"  - {feature_names_display[col]}\")\n",
    "print()\n",
    "print(\"Modell-Performance:\")\n",
    "print(f\"  Accuracy: {successful['accuracy'].mean():.1%} (Mean)\")\n",
    "print(f\"  AUC: {successful['auc'].mean():.3f} (Mean)\")\n",
    "print(f\"  Pseudo R²: {successful['pseudo_r2'].mean():.3f} (Mean)\")\n",
    "print()\n",
    "print(\"Gespeicherte Dateien:\")\n",
    "print(f\"  - {OUTPUT_DIR / 'logistic_regression_results.csv'}\")\n",
    "print(f\"  - {OUTPUT_DIR / 'model_performance_overview.png'}\")\n",
    "print(f\"  - {plots_dir}/ ({len(models)} Koeffizienten-Plots)\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}