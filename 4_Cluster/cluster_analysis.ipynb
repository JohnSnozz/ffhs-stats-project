{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusteranalyse der Schweizer Gemeinden\n",
    "\n",
    "Diese Analyse gruppiert Schweizer Gemeinden basierend auf ihrem Abstimmungsverhalten.\n",
    "\n",
    "**Methoden:**\n",
    "1. K-Means Clustering\n",
    "2. Hierarchisches Clustering (Ward)\n",
    "3. DBSCAN (dichtebasiert)\n",
    "4. Gaussian Mixture Models (GMM)\n",
    "\n",
    "**Datengrundlage:** Rohdaten der Abstimmungen (Ja-Prozent pro Gemeinde und Vorlage)\n",
    "\n",
    "**Visualisierung:** Im PCA-Raum (aus vorheriger Analyse)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup und Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import pdist\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot-Einstellungen\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Datenbankverbindung\n",
    "DB_PATH = '../data/processed/swiss_votings.db'\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "print(\"Setup abgeschlossen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abstimmungsdaten laden\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    municipality_id,\n",
    "    municipality_name,\n",
    "    proposal_id,\n",
    "    ja_prozent\n",
    "FROM v_voting_results_analysis\n",
    "WHERE ja_prozent IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "df_raw = pd.read_sql_query(query, conn)\n",
    "print(f\"Rohdaten geladen: {len(df_raw):,} Zeilen\")\n",
    "\n",
    "# Pivot-Tabelle erstellen: Gemeinden x Vorlagen\n",
    "df_pivot = df_raw.pivot_table(\n",
    "    index=['municipality_id', 'municipality_name'],\n",
    "    columns='proposal_id',\n",
    "    values='ja_prozent',\n",
    "    aggfunc='first'\n",
    ")\n",
    "\n",
    "print(f\"Matrix: {df_pivot.shape[0]} Gemeinden × {df_pivot.shape[1]} Vorlagen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenbereinigung: Gemeinden/Vorlagen mit zu vielen fehlenden Werten entfernen\n",
    "MAX_MISSING_RATIO = 0.20\n",
    "\n",
    "# Vorlagen filtern\n",
    "missing_per_proposal = df_pivot.isnull().sum(axis=0)\n",
    "valid_proposals = missing_per_proposal[missing_per_proposal <= df_pivot.shape[0] * MAX_MISSING_RATIO].index\n",
    "df_filtered = df_pivot[valid_proposals]\n",
    "\n",
    "# Gemeinden filtern\n",
    "missing_per_municipality = df_filtered.isnull().sum(axis=1)\n",
    "valid_municipalities = missing_per_municipality[missing_per_municipality <= df_filtered.shape[1] * MAX_MISSING_RATIO].index\n",
    "df_filtered = df_filtered.loc[valid_municipalities]\n",
    "\n",
    "print(f\"Nach Filterung: {df_filtered.shape[0]} Gemeinden × {df_filtered.shape[1]} Vorlagen\")\n",
    "\n",
    "# Imputation: Fehlende Werte mit Spalten-Mittelwert füllen\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(df_filtered)\n",
    "\n",
    "# DataFrame für Referenz\n",
    "df_imputed = pd.DataFrame(X_imputed, index=df_filtered.index, columns=df_filtered.columns)\n",
    "\n",
    "# Standardisierung\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_imputed)\n",
    "\n",
    "print(f\"Daten standardisiert. Shape: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA für Visualisierung (aus vorheriger Analyse)\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# PCA-Scores als DataFrame\n",
    "df_pca = pd.DataFrame(\n",
    "    X_pca,\n",
    "    columns=['PC1', 'PC2', 'PC3'],\n",
    "    index=df_imputed.index\n",
    ").reset_index()\n",
    "\n",
    "print(f\"PCA berechnet. Erklärte Varianz: {pca.explained_variance_ratio_.sum()*100:.1f}%\")\n",
    "print(f\"  PC1: {pca.explained_variance_ratio_[0]*100:.1f}%\")\n",
    "print(f\"  PC2: {pca.explained_variance_ratio_[1]*100:.1f}%\")\n",
    "print(f\"  PC3: {pca.explained_variance_ratio_[2]*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bestimmung der optimalen Clusteranzahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow-Methode und Silhouette-Score für verschiedene k\n",
    "k_range = range(2, 15)\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "calinski = []\n",
    "davies = []\n",
    "\n",
    "print(\"Berechne Metriken für k = 2 bis 14...\")\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouettes.append(silhouette_score(X_scaled, labels))\n",
    "    calinski.append(calinski_harabasz_score(X_scaled, labels))\n",
    "    davies.append(davies_bouldin_score(X_scaled, labels))\n",
    "\n",
    "print(\"Fertig.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisierung der Metriken\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Elbow (Inertia)\n",
    "axes[0, 0].plot(k_range, inertias, 'bo-', markersize=8)\n",
    "axes[0, 0].set_xlabel('Anzahl Cluster (k)')\n",
    "axes[0, 0].set_ylabel('Inertia (Within-Cluster Sum of Squares)')\n",
    "axes[0, 0].set_title('Elbow-Methode')\n",
    "axes[0, 0].set_xticks(list(k_range))\n",
    "\n",
    "# Silhouette Score (höher = besser)\n",
    "axes[0, 1].plot(k_range, silhouettes, 'go-', markersize=8)\n",
    "axes[0, 1].set_xlabel('Anzahl Cluster (k)')\n",
    "axes[0, 1].set_ylabel('Silhouette Score')\n",
    "axes[0, 1].set_title('Silhouette Score (höher = besser)')\n",
    "axes[0, 1].set_xticks(list(k_range))\n",
    "best_k_sil = list(k_range)[np.argmax(silhouettes)]\n",
    "axes[0, 1].axvline(x=best_k_sil, color='red', linestyle='--', label=f'Best: k={best_k_sil}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Calinski-Harabasz Index (höher = besser)\n",
    "axes[1, 0].plot(k_range, calinski, 'mo-', markersize=8)\n",
    "axes[1, 0].set_xlabel('Anzahl Cluster (k)')\n",
    "axes[1, 0].set_ylabel('Calinski-Harabasz Index')\n",
    "axes[1, 0].set_title('Calinski-Harabasz Index (höher = besser)')\n",
    "axes[1, 0].set_xticks(list(k_range))\n",
    "\n",
    "# Davies-Bouldin Index (tiefer = besser)\n",
    "axes[1, 1].plot(k_range, davies, 'ro-', markersize=8)\n",
    "axes[1, 1].set_xlabel('Anzahl Cluster (k)')\n",
    "axes[1, 1].set_ylabel('Davies-Bouldin Index')\n",
    "axes[1, 1].set_title('Davies-Bouldin Index (tiefer = besser)')\n",
    "axes[1, 1].set_xticks(list(k_range))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cluster_metrics.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nBester Silhouette Score bei k = {best_k_sil}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means mit verschiedenen k-Werten\n",
    "k_values = [3, 4, 5, 6]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "kmeans_results = {}\n",
    "\n",
    "for i, k in enumerate(k_values):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    kmeans_results[k] = labels\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    \n",
    "    # Visualisierung im PCA-Raum\n",
    "    scatter = axes[i].scatter(\n",
    "        df_pca['PC1'], df_pca['PC2'],\n",
    "        c=labels, cmap='tab10', alpha=0.6, s=20\n",
    "    )\n",
    "    axes[i].set_xlabel('PC1: Liberal ← → Konservativ')\n",
    "    axes[i].set_ylabel('PC2: Populistisch ← → Establishment')\n",
    "    axes[i].set_title(f'K-Means (k={k}), Silhouette={sil:.3f}')\n",
    "    axes[i].axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "    axes[i].axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "    \n",
    "    # Cluster-Zentren im PCA-Raum\n",
    "    centers_pca = pca.transform(kmeans.cluster_centers_)\n",
    "    axes[i].scatter(centers_pca[:, 0], centers_pca[:, 1], \n",
    "                   c='red', marker='X', s=200, edgecolors='black', linewidths=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('kmeans_clustering.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailanalyse K-Means mit k=4 (oder bestem k)\n",
    "BEST_K = 4  # Anpassen basierend auf obiger Analyse\n",
    "\n",
    "kmeans_best = KMeans(n_clusters=BEST_K, random_state=42, n_init=10)\n",
    "df_pca['kmeans_cluster'] = kmeans_best.fit_predict(X_scaled)\n",
    "\n",
    "print(f\"K-Means Clustering mit k={BEST_K}\")\n",
    "print(f\"Silhouette Score: {silhouette_score(X_scaled, df_pca['kmeans_cluster']):.3f}\")\n",
    "print(f\"\\nCluster-Grössen:\")\n",
    "print(df_pca['kmeans_cluster'].value_counts().sort_index())\n",
    "\n",
    "# Beispiel-Gemeinden pro Cluster\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEISPIEL-GEMEINDEN PRO CLUSTER (K-Means)\")\n",
    "print(\"=\"*60)\n",
    "for cluster in range(BEST_K):\n",
    "    cluster_members = df_pca[df_pca['kmeans_cluster'] == cluster]\n",
    "    print(f\"\\nCluster {cluster} ({len(cluster_members)} Gemeinden):\")\n",
    "    # Gemeinden nahe am Zentrum\n",
    "    center = cluster_members[['PC1', 'PC2', 'PC3']].mean()\n",
    "    cluster_members = cluster_members.copy()\n",
    "    cluster_members['dist_to_center'] = np.sqrt(\n",
    "        (cluster_members['PC1'] - center['PC1'])**2 + \n",
    "        (cluster_members['PC2'] - center['PC2'])**2\n",
    "    )\n",
    "    for _, row in cluster_members.nsmallest(5, 'dist_to_center').iterrows():\n",
    "        print(f\"  {row['municipality_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hierarchisches Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchisches Clustering - Dendrogramm\n",
    "print(\"Berechne hierarchisches Clustering (Ward-Methode)...\")\n",
    "\n",
    "# Linkage berechnen\n",
    "Z = linkage(X_scaled, method='ward')\n",
    "\n",
    "# Dendrogramm (nur obere Ebenen für Übersichtlichkeit)\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "dendrogram(\n",
    "    Z,\n",
    "    truncate_mode='level',\n",
    "    p=5,  # Zeige nur 5 Ebenen\n",
    "    leaf_rotation=90,\n",
    "    leaf_font_size=8,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Gemeinden (gruppiert)')\n",
    "ax.set_ylabel('Distanz (Ward)')\n",
    "ax.set_title('Dendrogramm - Hierarchisches Clustering')\n",
    "\n",
    "# Horizontale Linien für verschiedene Cluster-Anzahlen\n",
    "ax.axhline(y=400, color='red', linestyle='--', label='~4 Cluster')\n",
    "ax.axhline(y=300, color='orange', linestyle='--', label='~6 Cluster')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('hierarchical_dendrogram.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchisches Clustering mit verschiedenen Cluster-Anzahlen\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "hier_results = {}\n",
    "\n",
    "for i, k in enumerate(k_values):\n",
    "    labels = fcluster(Z, k, criterion='maxclust') - 1  # 0-basiert\n",
    "    hier_results[k] = labels\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    \n",
    "    scatter = axes[i].scatter(\n",
    "        df_pca['PC1'], df_pca['PC2'],\n",
    "        c=labels, cmap='tab10', alpha=0.6, s=20\n",
    "    )\n",
    "    axes[i].set_xlabel('PC1: Liberal ← → Konservativ')\n",
    "    axes[i].set_ylabel('PC2: Populistisch ← → Establishment')\n",
    "    axes[i].set_title(f'Hierarchisch Ward (k={k}), Silhouette={sil:.3f}')\n",
    "    axes[i].axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "    axes[i].axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('hierarchical_clustering.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchisches Clustering - Detailanalyse\n",
    "df_pca['hier_cluster'] = fcluster(Z, BEST_K, criterion='maxclust') - 1\n",
    "\n",
    "print(f\"Hierarchisches Clustering mit k={BEST_K}\")\n",
    "print(f\"Silhouette Score: {silhouette_score(X_scaled, df_pca['hier_cluster']):.3f}\")\n",
    "print(f\"\\nCluster-Grössen:\")\n",
    "print(df_pca['hier_cluster'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEISPIEL-GEMEINDEN PRO CLUSTER (Hierarchisch)\")\n",
    "print(\"=\"*60)\n",
    "for cluster in range(BEST_K):\n",
    "    cluster_members = df_pca[df_pca['hier_cluster'] == cluster]\n",
    "    print(f\"\\nCluster {cluster} ({len(cluster_members)} Gemeinden):\")\n",
    "    center = cluster_members[['PC1', 'PC2', 'PC3']].mean()\n",
    "    cluster_members = cluster_members.copy()\n",
    "    cluster_members['dist_to_center'] = np.sqrt(\n",
    "        (cluster_members['PC1'] - center['PC1'])**2 + \n",
    "        (cluster_members['PC2'] - center['PC2'])**2\n",
    "    )\n",
    "    for _, row in cluster_members.nsmallest(5, 'dist_to_center').iterrows():\n",
    "        print(f\"  {row['municipality_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. DBSCAN (Dichtebasiertes Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN - Parameter-Suche\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# k-Distanz Plot zur Bestimmung von eps\n",
    "k = 10  # Anzahl Nachbarn\n",
    "neigh = NearestNeighbors(n_neighbors=k)\n",
    "neigh.fit(X_scaled)\n",
    "distances, _ = neigh.kneighbors(X_scaled)\n",
    "distances = np.sort(distances[:, k-1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(distances)\n",
    "ax.set_xlabel('Datenpunkte (sortiert)')\n",
    "ax.set_ylabel(f'{k}-Nachbar Distanz')\n",
    "ax.set_title('k-Distanz Plot zur eps-Bestimmung (Knie suchen)')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('dbscan_kdist.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Empfohlener eps-Bereich: {distances[int(len(distances)*0.9)]:.1f} - {distances[int(len(distances)*0.95)]:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN mit verschiedenen eps-Werten\n",
    "eps_values = [8, 10, 12, 15]\n",
    "min_samples = 10\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "dbscan_results = {}\n",
    "\n",
    "for i, eps in enumerate(eps_values):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = dbscan.fit_predict(X_scaled)\n",
    "    \n",
    "    dbscan_results[eps] = labels\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise = (labels == -1).sum()\n",
    "    \n",
    "    # Silhouette nur wenn > 1 Cluster\n",
    "    if n_clusters > 1:\n",
    "        # Ohne Noise-Punkte\n",
    "        mask = labels != -1\n",
    "        if mask.sum() > n_clusters:\n",
    "            sil = silhouette_score(X_scaled[mask], labels[mask])\n",
    "        else:\n",
    "            sil = 0\n",
    "    else:\n",
    "        sil = 0\n",
    "    \n",
    "    # Visualisierung\n",
    "    scatter = axes[i].scatter(\n",
    "        df_pca['PC1'], df_pca['PC2'],\n",
    "        c=labels, cmap='tab10', alpha=0.6, s=20\n",
    "    )\n",
    "    # Noise-Punkte markieren\n",
    "    noise_mask = labels == -1\n",
    "    axes[i].scatter(\n",
    "        df_pca.loc[noise_mask, 'PC1'], \n",
    "        df_pca.loc[noise_mask, 'PC2'],\n",
    "        c='gray', marker='x', s=30, alpha=0.5, label=f'Noise ({n_noise})'\n",
    "    )\n",
    "    \n",
    "    axes[i].set_xlabel('PC1: Liberal ← → Konservativ')\n",
    "    axes[i].set_ylabel('PC2: Populistisch ← → Establishment')\n",
    "    axes[i].set_title(f'DBSCAN (eps={eps}): {n_clusters} Cluster, Sil={sil:.3f}')\n",
    "    axes[i].axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "    axes[i].axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "    axes[i].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('dbscan_clustering.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN Detailanalyse mit bestem eps\n",
    "BEST_EPS = 12  # Anpassen basierend auf obiger Analyse\n",
    "\n",
    "dbscan_best = DBSCAN(eps=BEST_EPS, min_samples=min_samples)\n",
    "df_pca['dbscan_cluster'] = dbscan_best.fit_predict(X_scaled)\n",
    "\n",
    "n_clusters = len(set(df_pca['dbscan_cluster'])) - (1 if -1 in df_pca['dbscan_cluster'].values else 0)\n",
    "n_noise = (df_pca['dbscan_cluster'] == -1).sum()\n",
    "\n",
    "print(f\"DBSCAN mit eps={BEST_EPS}, min_samples={min_samples}\")\n",
    "print(f\"Anzahl Cluster: {n_clusters}\")\n",
    "print(f\"Noise-Punkte (Ausreisser): {n_noise}\")\n",
    "print(f\"\\nCluster-Grössen:\")\n",
    "print(df_pca['dbscan_cluster'].value_counts().sort_index())\n",
    "\n",
    "# Ausreisser-Gemeinden\n",
    "if n_noise > 0:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"AUSREISSER-GEMEINDEN (Noise, n={n_noise})\")\n",
    "    print(\"=\"*60)\n",
    "    outliers = df_pca[df_pca['dbscan_cluster'] == -1]\n",
    "    for _, row in outliers.head(20).iterrows():\n",
    "        print(f\"  {row['municipality_name']} (PC1={row['PC1']:.1f}, PC2={row['PC2']:.1f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gaussian Mixture Models (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMM - Modellselektion mit BIC/AIC\n",
    "n_components_range = range(2, 12)\n",
    "bics = []\n",
    "aics = []\n",
    "\n",
    "print(\"Berechne GMM für verschiedene Komponentenzahlen...\")\n",
    "for n in n_components_range:\n",
    "    gmm = GaussianMixture(n_components=n, random_state=42, n_init=5)\n",
    "    gmm.fit(X_scaled)\n",
    "    bics.append(gmm.bic(X_scaled))\n",
    "    aics.append(gmm.aic(X_scaled))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(n_components_range, bics, 'bo-', label='BIC', markersize=8)\n",
    "ax.plot(n_components_range, aics, 'ro-', label='AIC', markersize=8)\n",
    "ax.set_xlabel('Anzahl Komponenten')\n",
    "ax.set_ylabel('Informationskriterium')\n",
    "ax.set_title('GMM Modellselektion (tiefer = besser)')\n",
    "ax.legend()\n",
    "ax.set_xticks(list(n_components_range))\n",
    "\n",
    "best_n_bic = list(n_components_range)[np.argmin(bics)]\n",
    "ax.axvline(x=best_n_bic, color='blue', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gmm_model_selection.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOptimale Komponentenzahl nach BIC: {best_n_bic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMM mit verschiedenen Komponentenzahlen\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "axes = axes.flatten()\n",
    "\n",
    "gmm_results = {}\n",
    "\n",
    "for i, k in enumerate(k_values):\n",
    "    gmm = GaussianMixture(n_components=k, random_state=42, n_init=5)\n",
    "    labels = gmm.fit_predict(X_scaled)\n",
    "    probs = gmm.predict_proba(X_scaled)\n",
    "    \n",
    "    gmm_results[k] = {'labels': labels, 'probs': probs}\n",
    "    sil = silhouette_score(X_scaled, labels)\n",
    "    \n",
    "    # Farbe nach Cluster, Transparenz nach Zugehörigkeits-Wahrscheinlichkeit\n",
    "    max_probs = probs.max(axis=1)\n",
    "    \n",
    "    scatter = axes[i].scatter(\n",
    "        df_pca['PC1'], df_pca['PC2'],\n",
    "        c=labels, cmap='tab10', alpha=max_probs*0.8, s=20\n",
    "    )\n",
    "    axes[i].set_xlabel('PC1: Liberal ← → Konservativ')\n",
    "    axes[i].set_ylabel('PC2: Populistisch ← → Establishment')\n",
    "    axes[i].set_title(f'GMM (k={k}), Silhouette={sil:.3f}')\n",
    "    axes[i].axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "    axes[i].axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gmm_clustering.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GMM Detailanalyse\n",
    "gmm_best = GaussianMixture(n_components=BEST_K, random_state=42, n_init=5)\n",
    "df_pca['gmm_cluster'] = gmm_best.fit_predict(X_scaled)\n",
    "df_pca['gmm_prob'] = gmm_best.predict_proba(X_scaled).max(axis=1)\n",
    "\n",
    "print(f\"GMM mit k={BEST_K}\")\n",
    "print(f\"Silhouette Score: {silhouette_score(X_scaled, df_pca['gmm_cluster']):.3f}\")\n",
    "print(f\"\\nCluster-Grössen:\")\n",
    "print(df_pca['gmm_cluster'].value_counts().sort_index())\n",
    "\n",
    "# Gemeinden mit unsicherer Zuordnung\n",
    "uncertain = df_pca[df_pca['gmm_prob'] < 0.6]\n",
    "print(f\"\\nGemeinden mit unsicherer Zuordnung (prob < 0.6): {len(uncertain)}\")\n",
    "if len(uncertain) > 0:\n",
    "    print(\"Beispiele:\")\n",
    "    for _, row in uncertain.head(10).iterrows():\n",
    "        print(f\"  {row['municipality_name']} (prob={row['gmm_prob']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Vergleich der Methoden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich der Clustering-Ergebnisse\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "methods = ['kmeans_cluster', 'hier_cluster', 'gmm_cluster']\n",
    "method_names = ['K-Means', 'Hierarchisch', 'GMM']\n",
    "\n",
    "# Wenn DBSCAN brauchbare Cluster hat, auch hinzufügen\n",
    "if df_pca['dbscan_cluster'].nunique() > 2:\n",
    "    methods.append('dbscan_cluster')\n",
    "    method_names.append('DBSCAN')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"VERGLEICH DER CLUSTERING-METHODEN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Metriken\n",
    "print(f\"\\n{'Methode':<15} {'Silhouette':>12} {'Calinski-H':>12} {'Davies-B':>12}\")\n",
    "print(\"-\"*55)\n",
    "\n",
    "for method, name in zip(methods, method_names):\n",
    "    labels = df_pca[method].values\n",
    "    # Filter out noise for DBSCAN\n",
    "    if 'dbscan' in method:\n",
    "        mask = labels != -1\n",
    "        if mask.sum() > len(set(labels[mask])):\n",
    "            sil = silhouette_score(X_scaled[mask], labels[mask])\n",
    "            cal = calinski_harabasz_score(X_scaled[mask], labels[mask])\n",
    "            dav = davies_bouldin_score(X_scaled[mask], labels[mask])\n",
    "        else:\n",
    "            sil, cal, dav = 0, 0, 999\n",
    "    else:\n",
    "        sil = silhouette_score(X_scaled, labels)\n",
    "        cal = calinski_harabasz_score(X_scaled, labels)\n",
    "        dav = davies_bouldin_score(X_scaled, labels)\n",
    "    \n",
    "    print(f\"{name:<15} {sil:>12.3f} {cal:>12.1f} {dav:>12.3f}\")\n",
    "\n",
    "# Übereinstimmung zwischen Methoden (Adjusted Rand Index)\n",
    "print(\"\\n\" + \"-\"*55)\n",
    "print(\"Adjusted Rand Index (Übereinstimmung zwischen Methoden):\")\n",
    "print(\"-\"*55)\n",
    "\n",
    "for i, (m1, n1) in enumerate(zip(methods[:-1], method_names[:-1])):\n",
    "    for m2, n2 in zip(methods[i+1:], method_names[i+1:]):\n",
    "        ari = adjusted_rand_score(df_pca[m1], df_pca[m2])\n",
    "        print(f\"  {n1} vs {n2}: {ari:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finale Visualisierung: Beste Methode\n",
    "FINAL_METHOD = 'kmeans_cluster'  # Anpassen basierend auf Vergleich\n",
    "FINAL_NAME = 'K-Means'\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# PC1 vs PC2\n",
    "scatter = axes[0].scatter(\n",
    "    df_pca['PC1'], df_pca['PC2'],\n",
    "    c=df_pca[FINAL_METHOD], cmap='tab10', alpha=0.6, s=25\n",
    ")\n",
    "axes[0].set_xlabel('PC1: Liberal ← → Konservativ', fontsize=12)\n",
    "axes[0].set_ylabel('PC2: Populistisch ← → Establishment', fontsize=12)\n",
    "axes[0].set_title(f'{FINAL_NAME} Clustering (PC1 vs PC2)', fontsize=14)\n",
    "axes[0].axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "axes[0].axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# PC1 vs PC3\n",
    "scatter = axes[1].scatter(\n",
    "    df_pca['PC1'], df_pca['PC3'],\n",
    "    c=df_pca[FINAL_METHOD], cmap='tab10', alpha=0.6, s=25\n",
    ")\n",
    "axes[1].set_xlabel('PC1: Liberal ← → Konservativ', fontsize=12)\n",
    "axes[1].set_ylabel('PC3: Technokratisch ← → Ökologisch', fontsize=12)\n",
    "axes[1].set_title(f'{FINAL_NAME} Clustering (PC1 vs PC3)', fontsize=14)\n",
    "axes[1].axhline(y=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "axes[1].axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(scatter, ax=axes[1])\n",
    "cbar.set_label('Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('final_clustering.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Cluster-Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster-Profile basierend auf PCA-Koordinaten\n",
    "print(\"=\"*80)\n",
    "print(\"CLUSTER-PROFILE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for cluster in sorted(df_pca[FINAL_METHOD].unique()):\n",
    "    if cluster == -1:\n",
    "        continue  # Skip noise\n",
    "    \n",
    "    members = df_pca[df_pca[FINAL_METHOD] == cluster]\n",
    "    \n",
    "    print(f\"\\n{'-'*60}\")\n",
    "    print(f\"CLUSTER {cluster} ({len(members)} Gemeinden)\")\n",
    "    print(f\"{'-'*60}\")\n",
    "    \n",
    "    # Mittlere PCA-Koordinaten\n",
    "    pc1_mean = members['PC1'].mean()\n",
    "    pc2_mean = members['PC2'].mean()\n",
    "    pc3_mean = members['PC3'].mean()\n",
    "    \n",
    "    # Interpretation\n",
    "    lib_kon = \"LIBERAL\" if pc1_mean > 5 else (\"KONSERVATIV\" if pc1_mean < -5 else \"moderat\")\n",
    "    est_pop = \"ESTABLISHMENT\" if pc2_mean > 5 else (\"POPULISTISCH\" if pc2_mean < -5 else \"gemischt\")\n",
    "    oeko_tech = \"ÖKOLOGISCH\" if pc3_mean > 3 else (\"TECHNOKRATISCH\" if pc3_mean < -3 else \"neutral\")\n",
    "    \n",
    "    print(f\"  Mittlere Koordinaten:\")\n",
    "    print(f\"    PC1 (Lib-Kon): {pc1_mean:+.1f} → {lib_kon}\")\n",
    "    print(f\"    PC2 (Est-Pop): {pc2_mean:+.1f} → {est_pop}\")\n",
    "    print(f\"    PC3 (Öko-Tec): {pc3_mean:+.1f} → {oeko_tech}\")\n",
    "    \n",
    "    # Typische Gemeinden (nahe am Zentroid)\n",
    "    members = members.copy()\n",
    "    members['dist'] = np.sqrt(\n",
    "        (members['PC1'] - pc1_mean)**2 + \n",
    "        (members['PC2'] - pc2_mean)**2 +\n",
    "        (members['PC3'] - pc3_mean)**2\n",
    "    )\n",
    "    \n",
    "    print(f\"  \\n  Typische Gemeinden:\")\n",
    "    for _, row in members.nsmallest(8, 'dist').iterrows():\n",
    "        print(f\"    - {row['municipality_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export der Ergebnisse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export der Cluster-Zuordnungen\n",
    "export_df = df_pca[['municipality_id', 'municipality_name', 'PC1', 'PC2', 'PC3',\n",
    "                    'kmeans_cluster', 'hier_cluster', 'gmm_cluster', 'dbscan_cluster']].copy()\n",
    "\n",
    "export_df.to_csv('municipality_clusters.csv', index=False)\n",
    "print(\"Cluster-Zuordnungen exportiert nach: municipality_clusters.csv\")\n",
    "\n",
    "# Zusammenfassung\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ZUSAMMENFASSUNG\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDatenbasis: {len(df_pca)} Gemeinden, {df_imputed.shape[1]} Abstimmungen\")\n",
    "print(f\"\\nGetestete Methoden:\")\n",
    "print(f\"  - K-Means (k={BEST_K})\")\n",
    "print(f\"  - Hierarchisch Ward (k={BEST_K})\")\n",
    "print(f\"  - DBSCAN (eps={BEST_EPS})\")\n",
    "print(f\"  - Gaussian Mixture (k={BEST_K})\")\n",
    "print(f\"\\nVisualisierung: Im PCA-Raum (3 Dimensionen)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datenbankverbindung schliessen\n",
    "conn.close()\n",
    "print(\"Analyse abgeschlossen.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
